{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b28088a3",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "TODO\n",
    "\n",
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746a805",
   "metadata": {
    "scrolled": false,
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install openpyxl > /dev/null 2>&1\n",
    "!pip install jupyterlab-widgets > /dev/null 2>&1\n",
    "!pip install jsfileupload > /dev/null 2>&1\n",
    "!pip install pyxlsb > /dev/null 2>&1\n",
    "!pip install sklearn > /dev/null 2>&1\n",
    "!pip install scipy > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c2801",
   "metadata": {},
   "source": [
    "## Set an arbitrary random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2deec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e92bd3",
   "metadata": {},
   "source": [
    "## Run the pre-imputation script\n",
    "\n",
    "AKA load the data, truncate it and create gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8057fb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run helpers/pre_imputation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ed199",
   "metadata": {},
   "source": [
    "## Define the hotdeck imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e907ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers/hotdeck.ipynb\n",
    "\n",
    "# Config\n",
    "step = timedelta(seconds=300)\n",
    "surrounding_duration = timedelta(seconds=3600)\n",
    "\n",
    "# Internal globals\n",
    "progress_bar = None\n",
    "cached_donors = None\n",
    "start_time = 0\n",
    "donors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47757cbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "async def hotdeck(receiver: pd.DataFrame, config: object) -> pd.DataFrame:\n",
    "    global file_select, donors, start_time, total_gaps, progress_bar\n",
    "\n",
    "    custom_progress_status = widgets.HTML()\n",
    "    if cached_donors == None:\n",
    "        donors = await prompt_donor_selection()\n",
    "        display(custom_progress_status)\n",
    "        load_donors_in_cache(donors, custom_progress_status)\n",
    "    else:\n",
    "        display(custom_progress_status)\n",
    "\n",
    "    receiver_cp = receiver.copy()\n",
    "    gap_indices_cp = config[\"current_gap_indices\"].copy()\n",
    "\n",
    "    # Init global variables\n",
    "    start_time = datetime.now()\n",
    "    progress_bar = widgets.IntProgress(min=0, max=len(gap_indices_cp), value=0)\n",
    "    display(progress_bar)\n",
    "\n",
    "    threads = start_workers(receiver_cp, gap_indices_cp, custom_progress_status)\n",
    "    impute(receiver_cp, gap_indices_cp, custom_progress_status)\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    custom_progress_status.value = f\"Time taken: {(datetime.now() - start_time)}\"\n",
    "    return receiver_cp\n",
    "\n",
    "\n",
    "def impute(receiver: pd.DataFrame, gap_indices: [[datetime]], custom_progress_status: widgets.HTML) -> None:\n",
    "    global surrounding_duration, column_name, donors\n",
    "\n",
    "    while (gap := pop_gap(gap_indices)) != None:\n",
    "        display_progress(custom_progress_status, len(gap_indices))\n",
    "\n",
    "        gap_start_idx, gap_end_idx = get_gap_boundaries(receiver, gap[0], gap[-1])\n",
    "        gap_start_time = receiver.index[gap_start_idx]\n",
    "        gap_end_time = receiver.index[gap_end_idx]\n",
    "\n",
    "        duration_before, duration_after = get_sampling_durations(receiver, gap_start_idx, gap_end_idx, gap_start_time, gap_end_time)\n",
    "\n",
    "        before = get_normalized_dataframe(receiver, gap_start_time - duration_before, gap_start_time)\n",
    "        after = get_normalized_dataframe(receiver, gap_end_time, gap_end_time + duration_after)\n",
    "\n",
    "        donor_start_time = gap_start_time - (duration_before + surrounding_duration)\n",
    "        donor_end_time = gap_end_time + (duration_after + surrounding_duration)\n",
    "\n",
    "        scoreboard = []\n",
    "\n",
    "        for file in donors:\n",
    "            donor = get_donor(file, donor_start_time, donor_end_time)\n",
    "            if len(donor.index) != 0:\n",
    "                scoreboard += scan_donor(before.copy(), after.copy(), file, donor)\n",
    "\n",
    "        fill_gap(receiver, gap, gap_start_time, gap_end_time, scoreboard)\n",
    "\n",
    "\n",
    "def scan_donor(before: pd.DataFrame, after: pd.DataFrame, donor_filename: str, donor: pd.DataFrame) -> [dict]:\n",
    "    global step, column_name\n",
    "\n",
    "    scores = []\n",
    "    original_sample_mean = (before[column_name].mean() + after[column_name].mean()) / 2\n",
    "\n",
    "    # Shift the comparison sample the start of the donor sample\n",
    "    x_offset = before.index[0] - donor.index[0]\n",
    "    x_offset -= x_offset % step\n",
    "    before.index = before.index - x_offset\n",
    "    after.index = after.index - x_offset\n",
    "\n",
    "    while after.index[-1] <= donor.index[-1]:\n",
    "        # Donor comparison samples\n",
    "        donor_before = get_normalized_dataframe(donor, before.index[0], before.index[-1])\n",
    "        donor_after = get_normalized_dataframe(donor, after.index[0], after.index[-1])\n",
    "\n",
    "        # We need to take into account the previous Y-axis shifting\n",
    "        y_offset, adjusted_y_offset = get_y_offsets(original_sample_mean, before, after, donor_before, donor_after)\n",
    "\n",
    "        # Apply the offset\n",
    "        before[column_name] = before[column_name] + adjusted_y_offset\n",
    "        after[column_name] = after[column_name] + adjusted_y_offset\n",
    "\n",
    "        scores.append({\n",
    "            \"score\": get_similarity_score(before, after, donor_before, donor_after),\n",
    "            \"x_offset\": x_offset,\n",
    "            \"y_offset\": y_offset,\n",
    "            \"start\": before.index[0],\n",
    "            \"end\": after.index[-1],\n",
    "            \"filename\": donor_filename\n",
    "        })\n",
    "\n",
    "        # Shift the comparison sample to the next step\n",
    "        x_offset -= step\n",
    "        before.index = before.index + step\n",
    "        after.index = after.index + step\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da8809",
   "metadata": {},
   "source": [
    "## Run the imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78f2ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "imputation_status = widgets.HTML(value=\"\")\n",
    "display(imputation_status)\n",
    "\n",
    "imputed_dfs = []\n",
    "\n",
    "async def do_imputation():\n",
    "    global imputed_dfs\n",
    "    for i in range(len(dfs_with_gaps)):\n",
    "        imputation_status.value = f\"Running imputation... ({i}/{len(dfs_with_gaps)})\"\n",
    "        dataset_config['current_gap_indices'] = gaps_indices[i]\n",
    "        result = await hotdeck(dfs_with_gaps[i], dataset_config)\n",
    "        imputed_dfs.append(result)\n",
    "    imputation_status.value = \"Imputation complete\"\n",
    "\n",
    "_ = asyncio.ensure_future(do_imputation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ebae4",
   "metadata": {},
   "source": [
    "## Run the post imputation script\n",
    "\n",
    "AKA visualize and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fe795",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run helpers/evaluate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b4be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
