{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import multiprocessing\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from ipywidgets import widgets\n",
    "import time\n",
    "\n",
    "gap_indices_lock = threading.RLock()\n",
    "\n",
    "def fill_gap(receiver: pd.DataFrame, gap: [datetime], gap_start_time: datetime, gap_end_time: datetime, scoreboard: [dict]) -> None:\n",
    "    global column_name\n",
    "\n",
    "    if len(scoreboard) != 0:\n",
    "        scoreboard.sort(key=lambda it: it[\"score\"])\n",
    "        best = scoreboard[0]\n",
    "        donor = get_donor(best[\"filename\"], best[\"start\"], best[\"end\"])\n",
    "        donor.index = donor.index + best[\"x_offset\"]\n",
    "        donor[column_name] = donor[column_name] - best[\"y_offset\"]\n",
    "    else:\n",
    "        donor = pd.DataFrame({\n",
    "            column_name: [\n",
    "                receiver[column_name][gap_start_time],\n",
    "                receiver[column_name][gap_end_time]\n",
    "            ]},\n",
    "            index=[gap_start_time, gap_end_time]\n",
    "        )\n",
    "\n",
    "    transpose_data(donor, receiver, gap)\n",
    "\n",
    "\n",
    "def filter_compatible_files(files: [str]) -> [str]:\n",
    "    global sheet_name\n",
    "    return [file for file in files if \".csv\" in file or sheet_name in pd.ExcelFile(config[\"upload_dir\"] + file, engine='openpyxl').sheet_names]\n",
    "\n",
    "\n",
    "def get_similarity_score(before: pd.DataFrame, after: pd.DataFrame, donor_before: pd.DataFrame, donor_after: pd.DataFrame) -> float:\n",
    "    return max([\n",
    "        directed_hausdorff(before, donor_before)[0] + directed_hausdorff(after, donor_after)[0],\n",
    "        directed_hausdorff(donor_before, before)[0] + directed_hausdorff(donor_after, after)[0]\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_y_offsets(original_sample_mean: float, before: pd.DataFrame, after: pd.DataFrame, donor_before: pd.DataFrame, donor_after: pd.DataFrame) -> tuple:\n",
    "    global column_name\n",
    "\n",
    "    mean_receiver = (before[column_name].mean() + after[column_name].mean()) / 2\n",
    "    mean_donor = (donor_before[column_name].mean() + donor_after[column_name].mean()) / 2\n",
    "    adjusted_y_offset = mean_donor - mean_receiver\n",
    "    y_offset = adjusted_y_offset - (original_sample_mean - mean_receiver)\n",
    "    return y_offset, adjusted_y_offset\n",
    "\n",
    "\n",
    "def get_normalized_dataframe(df: pd.DataFrame, start_time: datetime, end_time: datetime) -> pd.DataFrame:\n",
    "    start_idx = df.index.get_loc(start_time if start_time >= df.index[0] else df.index[0], 'pad')\n",
    "    view = df[df.index >= df.index[start_idx]]\n",
    "\n",
    "    if end_time < view.index[-1]:\n",
    "        end_idx = view.index.get_loc(end_time, 'bfill')\n",
    "        view = view[view.index <= view.index[end_idx]]\n",
    "\n",
    "    start_time_missing = view.index[0] != start_time\n",
    "    end_time_missing = view.index[-1] != end_time\n",
    "\n",
    "    cp = view.copy()\n",
    "\n",
    "    if start_time_missing or end_time_missing:\n",
    "        if start_time_missing:\n",
    "            cp.loc[start_time] = [np.nan]\n",
    "        if end_time_missing:\n",
    "            cp.loc[end_time] = [np.nan]\n",
    "        cp.sort_index(inplace=True)\n",
    "        cp.interpolate(method=\"index\", inplace=True)\n",
    "        cp = cp[cp.index >= start_time]\n",
    "        cp = cp[cp.index <= end_time]\n",
    "\n",
    "    return cp\n",
    "\n",
    "\n",
    "def get_donor(filepath: str, start_time: datetime = None, end_time: datetime = None) -> None:\n",
    "    global cached_donors\n",
    "\n",
    "    donor = cached_donors[filepath].copy()\n",
    "    if start_time != None:\n",
    "        donor = donor[donor.index >= start_time]\n",
    "    if end_time != None:\n",
    "        donor = donor[donor.index <= end_time]\n",
    "    return donor\n",
    "\n",
    "\n",
    "def load_donors_in_cache(donors: [str], custom_progress_status: widgets.HTML):\n",
    "    global sheet_name, column_name, cached_donors\n",
    "\n",
    "    custom_progress_status.value = f\"Hotdeck starting, loading {len(donors)} donors...\"\n",
    "    cached_donors = dict()\n",
    "    for filename in donors:\n",
    "        with open(config[\"upload_dir\"] + filename, 'rb') as file:\n",
    "            cached_donors[filename] = parse_uploaded_file_sync(filename, file.read(), sheet_name, column_name)\n",
    "\n",
    "\n",
    "def transpose_data(donor: str, receiver: str, gap_indices: [datetime]) -> None:\n",
    "    global column_name\n",
    "\n",
    "    for gap_idx in gap_indices:\n",
    "        if gap_idx not in donor.index:\n",
    "            donor.loc[gap_idx] = [np.nan]\n",
    "\n",
    "    donor.sort_index(inplace=True)\n",
    "    donor.interpolate(method=\"index\", inplace=True)\n",
    "\n",
    "    for gap_idx in gap_indices:\n",
    "        receiver[column_name][gap_idx] = donor[column_name][gap_idx]\n",
    "\n",
    "\n",
    "def get_gap_boundaries(df: pd.DataFrame, gap_start_time: datetime, gap_end_time: datetime) -> tuple:\n",
    "    gap_start_idx = df.index.get_loc(gap_start_time) - 1\n",
    "    gap_end_idx = df.index.get_loc(gap_end_time) + 1\n",
    "\n",
    "    if gap_start_idx < 0:\n",
    "        gap_start_idx = 0\n",
    "    if gap_end_idx >= len(df):\n",
    "        gap_end_idx = len(df) - 1\n",
    "\n",
    "    return gap_start_idx, gap_end_idx\n",
    "\n",
    "\n",
    "def pop_gap(gap_indices: [[datetime]]) -> [datetime]:\n",
    "    global gap_indices_lock\n",
    "    with gap_indices_lock:\n",
    "        gaps_left = len(gap_indices)\n",
    "        if gaps_left > 0:\n",
    "            return gap_indices.pop(0)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_sampling_durations(receiver: pd.DataFrame, gap_start_idx: int, gap_end_idx: int, gap_start_time: datetime, gap_end_time: datetime) -> tuple:\n",
    "    global column_name\n",
    "\n",
    "    gap_duration = gap_end_time - gap_start_time\n",
    "    max_duration = gap_duration * 1.5 if gap_duration > timedelta(seconds=1800) else timedelta(seconds=1800)\n",
    "    index_count = len(receiver.index)\n",
    "\n",
    "    duration_before = timedelta(seconds=0)\n",
    "    while gap_start_idx > 0 \\\n",
    "            and duration_before < max_duration \\\n",
    "            and np.isnan(receiver[column_name][receiver.index[gap_start_idx]]) == False:\n",
    "        duration_before = gap_start_time - receiver.index[gap_start_idx]\n",
    "        gap_start_idx -= 1\n",
    "\n",
    "    duration_after = timedelta(seconds=0)\n",
    "    while gap_end_idx < index_count \\\n",
    "            and duration_after < max_duration \\\n",
    "            and np.isnan(receiver[column_name][receiver.index[gap_end_idx]]) == False:\n",
    "        duration_after = receiver.index[gap_end_idx] - gap_end_time\n",
    "        gap_end_idx += 1\n",
    "\n",
    "    return duration_before, duration_after\n",
    "\n",
    "\n",
    "def display_progress(custom_progress_status: widgets.HTML, gaps_left: int) -> None:\n",
    "    global start_time, progress_bar\n",
    "    gaps_done = progress_bar.max - gaps_left\n",
    "    progress_bar.description = \"%d/%d: \" % (gaps_done, progress_bar.max)\n",
    "    progress_bar.value = gaps_done\n",
    "\n",
    "    elapsed = datetime.now() - start_time\n",
    "    total_time_estimate = (elapsed / (progress_bar.max - gaps_left + 1)) * progress_bar.max\n",
    "    eta = total_time_estimate - elapsed\n",
    "    eta -= timedelta(microseconds=eta.microseconds)\n",
    "    elapsed -= timedelta(microseconds=elapsed.microseconds)\n",
    "    custom_progress_status.value = f\"ETA: {eta} ({elapsed} elapsed)\"\n",
    "\n",
    "\n",
    "def start_workers(receiver: pd.DataFrame, gap_indices: [[datetime]], custom_progress_status: widgets.HTML) -> [threading.Thread]:\n",
    "    threads = []\n",
    "    thread_count = max(multiprocessing.cpu_count() - 1, 31)\n",
    "    for idx in range(thread_count - 1):\n",
    "        threads.append(threading.Thread(\n",
    "            target=impute,\n",
    "            args=(receiver, gap_indices, custom_progress_status)\n",
    "        ))\n",
    "        threads[idx].start()\n",
    "    return threads\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
